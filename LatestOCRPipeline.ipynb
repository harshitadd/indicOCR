{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LatestOCRPipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMlVm8ekQw/SJORX4IQnQph",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitadd/AI4BharatTranslation/blob/main/LatestOCRPipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMdaBYIoP6_H"
      },
      "source": [
        "import logging\n",
        "import os\n",
        "import json\n",
        "from time import sleep\n",
        "import glob\n",
        "import requests"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT1j3nuiP6_I"
      },
      "source": [
        "word_url = \"https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/async/initiate\"\n",
        "google_url = \"https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/async/initiate\"\n",
        "layout_url = \"https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/async/initiate\"\n",
        "segmenter_url = \"https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/async/initiate\"\n",
        "bs_url =\"https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/jobs/search/bulk\"\n",
        "evaluator_url  = \"https://auth.anuvaad.org/anuvaad-etl/document-processor/evaluator/v0/process\"\n",
        "download_url =\"https://auth.anuvaad.org/download/\"\n",
        "upload_url = 'https://auth.anuvaad.org/anuvaad-api/file-uploader/v0/upload-file'\n",
        "token = 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyTmFtZSI6ImhhcnNoaXRhZGRAZ21haWwuY29tIiwicGFzc3dvcmQiOiJiJyQyYiQxMiR3UGFvand4QmtVUGxuZnB0RWtDVW1lSXVlVmxDblRFSHpXbFpjUnZnckJUb0J4clI0SEpuSyciLCJleHAiOjE2MTUyNjExNDV9.PYJRr78L765Ra4g2Vm3vxfGKw9f8yURZwiqF9iVJTEI'\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq3UMkV6OwvW"
      },
      "source": [
        "headers = {'auth-token' :token }\r\n",
        "language = 'detect'\r\n",
        "file_format = 'PDF'\r\n",
        "\r\n",
        "evaluation_level = 'LINE'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npfAt8fpQZCA",
        "outputId": "2c507465-5078-4174-8ff4-f9e3439e8402"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOEiDE9-P6_I"
      },
      "source": [
        "parent_folder = \"/content/drive/MyDrive/Te/\"\n",
        "source_pdfs = \"/content/drive/MyDrive/Te/\"\n",
        "parsed_pdf_dir = \"/content/drive/MyDrive/Te/parsed/\"\n",
        "text_dir = \"/content/drive/MyDrive/Te/text/\"\n",
        "sentences_dir = \"/content/drive/MyDrive/Te/sent/\"\n",
        "aligned_sentences_path = \"/content/drive/MyDrive/Te/aligned/\"\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVq8hmgtP6_J"
      },
      "source": [
        "def google_ocr(word_url,headers,pdf_name):\n",
        "    \n",
        "    file = {\n",
        "       \"files\": [\n",
        "        {\n",
        "            \"locale\": \"en\",\n",
        "            \"path\": pdf_name,\n",
        "            \"type\": file_format,\n",
        "            \"config\":{\n",
        "        \"OCR\": {\n",
        "          \"option\": \"HIGH_ACCURACY\",\n",
        "          \"language\": language\n",
        "        }\n",
        "        }}\n",
        "    ],\n",
        "    \"workflowCode\": \"WF_A_OGV\"\n",
        "    }\n",
        "    res = requests.post(word_url,json=file,headers=headers)\n",
        "    return res.json()\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "082r5MXVP6_J"
      },
      "source": [
        "def upload_file(pdf_file,headers,url):\n",
        "    files = [\n",
        "        ('file',(open(pdf_file,'rb')))] \n",
        "\n",
        "    response = requests.post(url, headers=headers, files=files)\n",
        "    \n",
        "    return response.json()\n",
        "    response.json()\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myhs2ktDP6_K"
      },
      "source": [
        "def download_file(download_url,headers,outputfile,f_type='json'):\n",
        "    download_url =download_url+str(outputfile)\n",
        "    res = requests.get(download_url,headers=headers)\n",
        "    if f_type == 'json':\n",
        "        return res.json()\n",
        "    else :\n",
        "        return res.content"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc75CcCoP6_K"
      },
      "source": [
        "def save_json(path,res):\n",
        "    with open(path, \"w\", encoding='utf8') as write_file:\n",
        "        json.dump(res, write_file,ensure_ascii=False )\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyiyvcVjP6_K"
      },
      "source": [
        "def bulk_search(job_id,bs_url,headers):\n",
        "    bs_request = {\n",
        "    \"jobIDs\": [job_id],\n",
        "    \"taskDetails\":\"true\"\n",
        "    }\n",
        "    print(job_id)\n",
        "    res = requests.post(bs_url,json=bs_request,headers=headers, timeout = 10000)\n",
        "    print(res.json())\n",
        "    prev_progress = \"\"\n",
        "   \n",
        "    while(1):\n",
        "        \n",
        "        progress = res.json()['jobs'][0]['status']\n",
        "       \n",
        "        if progress in ['COMPLETED','FAILED']:\n",
        "            print(progress)\n",
        "            outputfile = res.json()['jobs'][0]['taskDetails'][0]['output'][0]['outputFile']\n",
        "            print(outputfile)\n",
        "            print(job_id)\n",
        "            return outputfile\n",
        "            break\n",
        "        sleep(0.5)\n",
        "        if progress != prev_progress:\n",
        "            print(progress)\n",
        "            prev_progress = progress\n",
        "        res = requests.post(bs_url,json=bs_request,headers=headers, timeout = 10000)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymcVysLkP6_L"
      },
      "source": [
        "def bulk_search_all(job_id,bs_url,headers):\n",
        "    bs_request = {\n",
        "    \"jobIDs\": [job_id],\n",
        "    \"taskDetails\":\"true\"\n",
        "    }\n",
        "    print(job_id)\n",
        "    res = requests.post(bs_url,json=bs_request,headers=headers, timeout = 10000)\n",
        "    print(res.json())\n",
        "    \n",
        "   \n",
        "    while(1):\n",
        "        \n",
        "        progress = res.json()['jobs'][0]['status']\n",
        "       \n",
        "        if progress in ['COMPLETED','FAILED']:\n",
        "            print(progress)\n",
        "            outputfile = res.json()['jobs'][0]['taskDetails'][0]['output'][0]['outputFile']\n",
        "            print(outputfile)\n",
        "            print(job_id)\n",
        "            return outputfile\n",
        "            break\n",
        "        sleep(0.5)\n",
        "        print(progress)\n",
        "        res = requests.post(bs_url,json=bs_request,headers=headers, timeout = 10000)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzlipU-ZP6_L"
      },
      "source": [
        "def execute_module(module,url,input_file,module_code,pdf_dir,overwirte=True , draw=True):\n",
        "    \n",
        "        \n",
        "        output_path = os.path.join(pdf_dir,'{}.json'.format(module_code))\n",
        "        if os.path.exists(output_path) and not overwirte:\n",
        "            print(' loading *****************{}'.format(module_code ))\n",
        "            with open(output_path,'r') as wd_file :\n",
        "                response = json.load(wd_file)\n",
        "                \n",
        "            wf_res = pdf_dir + '/{}_wf.json'.format(module_code)\n",
        "            with open(wf_res,'r') as wd_file :\n",
        "                json_file = json.load(wd_file) \n",
        "            job_to_add = (pdf_dir)\n",
        "\n",
        "        else :\n",
        "            if module_code in ['wd','gv']:\n",
        "                res = upload_file(input_file,headers,upload_url)\n",
        "                print('upload response **********', res)\n",
        "                pdf_name = res['data']\n",
        "                response = module(url,headers,pdf_name)\n",
        "            \n",
        "            else : \n",
        "                response = module(url,headers,input_file)\n",
        "                \n",
        "                if 'eval' in module_code :\n",
        "                    json_file = response['outputFile']\n",
        "                    response = download_file(download_url,headers,json_file)\n",
        "                    save_json(output_path,response)\n",
        "                    return json_file,response\n",
        "                \n",
        "            \n",
        "            print(' response *****************{} {}'.format(module_code ,response ))\n",
        "            job_id = response['jobID']\n",
        "            \n",
        "            job_to_add = (job_id,bs_url,headers,pdf_dir,module_code,output_path)\n",
        "        return job_to_add\n",
        "\n",
        "        \n",
        "            \n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJU1VjifP6_M"
      },
      "source": [
        "def evaluate__and_save_input(pdf_files,output_dir,headers,word_url,layout_url,download_url,upload_url,bs_url):\n",
        "    word_responses   = {}\n",
        "    layout_responses = {}\n",
        "    segmenter_responses = []\n",
        "    jobs_to_track = []\n",
        "    for pdf in pdf_files:\n",
        "        try :\n",
        "            pdf_name = pdf.split('/')[-1].split('.')[0]\n",
        "            parent_folder_name = pdf.split('/')[-2]\n",
        "            print(pdf , ' is being processed')\n",
        "            pdf_output_dir = os.path.join(output_dir,parent_folder_name,pdf_name)\n",
        "            os.system('mkdir -p \"{}\"'.format(pdf_output_dir))\n",
        "\n",
        " \n",
        "            job_to_add = execute_module(google_ocr,google_url,input_file=pdf,\\\n",
        "                           module_code='gv',pdf_dir=pdf_output_dir,overwirte=False , draw=False)\n",
        "            \n",
        "            jobs_to_track.append(job_to_add)\n",
        "          \n",
        "        except Exception as e : \n",
        "            print(e)\n",
        "            logging.error('error in file {}  \\n {}'.format(pdf_name,e))\n",
        "\n",
        " \n",
        "    for job in jobs_to_track:\n",
        "        print(\"----------\")\n",
        "        print(job)\n",
        "        job_id,bs_url,headers,pdf_dir,module_code,output_path = job\n",
        "        json_file = bulk_search(job_id,bs_url,headers)\n",
        "        save_json(pdf_dir + '/{}_wf.json'.format(module_code),json_file)   \n",
        "        print('bulk search  response **************',json_file )\n",
        "        response = download_file(download_url,headers,json_file)\n",
        "        save_json(output_path,response)\n",
        "\n",
        "    print(\"----------------\")\n",
        "    print(jobs_to_track)\n",
        "    print(\"----------------\")\n",
        "    return jobs_to_track"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKvYZUYVP6_N"
      },
      "source": [
        "def main(path,headers,word_url,layout_url,download_url,upload_url,bs_url):\n",
        "        pdf_names = glob.glob(path + '/*/*.pdf')[:2]\n",
        "        pdf_names.reverse()\n",
        "        return evaluate__and_save_input(pdf_names,parsed_pdf_dir,headers,word_url,layout_url,download_url,upload_url,bs_url)\n",
        "        "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04ptF-t-P6_O",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb0a2bd6-f121-4706-d553-8acf3b58f14d"
      },
      "source": [
        "main(source_pdfs,headers,word_url,layout_url,download_url,upload_url,bs_url)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Te/12/s12_en.pdf  is being processed\n",
            "upload response ********** {'data': 'fcb705ee-232f-4d63-b532-20eec1e89d32.pdf', 'http': {'status': 200}, 'ok': True, 'why': 'request successful'}\n",
            " response *****************gv {'active': True, 'input': {'files': [{'config': {'OCR': {'language': 'detect', 'option': 'HIGH_ACCURACY'}}, 'locale': 'en', 'path': 'fcb705ee-232f-4d63-b532-20eec1e89d32.pdf', 'type': 'PDF'}], 'workflowCode': 'WF_A_OGV'}, 'jobID': 'A_OGV-wGJKY-1615187332362', 'metadata': {'module': 'WORKFLOW-MANAGER', 'orgID': 'ANUVAAD', 'receivedAt': 1615187332362, 'requestID': 'a53275e2-8169-41ff-8c2f-9a73e79de294', 'sessionID': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyTmFtZSI6ImhhcnNoaXRhZGRAZ21haWwuY29tIiwicGFzc3dvcmQiOiJiJyQyYiQxMiR3UGFvand4QmtVUGxuZnB0RWtDVW1lSXVlVmxDblRFSHpXbFpjUnZnckJUb0J4clI0SEpuSyciLCJleHAiOjE2MTUyNjExNDV9.PYJRr78L765Ra4g2Vm3vxfGKw9f8yURZwiqF9iVJTEI', 'userID': '03e160d36bc34c8fb3a0fbb63e4b02701613729142248'}, 'startTime': 1615187332403, 'state': 'INITIATED', 'status': 'STARTED', 'taskDetails': [], 'workflowCode': 'WF_A_OGV'}\n",
            "/content/drive/MyDrive/Te/12/s12_te.pdf  is being processed\n",
            "upload response ********** {'data': '5e19ce0a-d643-4a34-bc0f-14c154b5a963.pdf', 'http': {'status': 200}, 'ok': True, 'why': 'request successful'}\n",
            " response *****************gv {'active': True, 'input': {'files': [{'config': {'OCR': {'language': 'detect', 'option': 'HIGH_ACCURACY'}}, 'locale': 'en', 'path': '5e19ce0a-d643-4a34-bc0f-14c154b5a963.pdf', 'type': 'PDF'}], 'workflowCode': 'WF_A_OGV'}, 'jobID': 'A_OGV-hHuim-1615187336810', 'metadata': {'module': 'WORKFLOW-MANAGER', 'orgID': 'ANUVAAD', 'receivedAt': 1615187336810, 'requestID': 'f5bf46ef-cf5e-47d0-98db-ce1b71b8fa7d', 'sessionID': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyTmFtZSI6ImhhcnNoaXRhZGRAZ21haWwuY29tIiwicGFzc3dvcmQiOiJiJyQyYiQxMiR3UGFvand4QmtVUGxuZnB0RWtDVW1lSXVlVmxDblRFSHpXbFpjUnZnckJUb0J4clI0SEpuSyciLCJleHAiOjE2MTUyNjExNDV9.PYJRr78L765Ra4g2Vm3vxfGKw9f8yURZwiqF9iVJTEI', 'userID': '03e160d36bc34c8fb3a0fbb63e4b02701613729142248'}, 'startTime': 1615187336852, 'state': 'INITIATED', 'status': 'STARTED', 'taskDetails': [], 'workflowCode': 'WF_A_OGV'}\n",
            "----------\n",
            "('A_OGV-wGJKY-1615187332362', 'https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/jobs/search/bulk', {'auth-token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyTmFtZSI6ImhhcnNoaXRhZGRAZ21haWwuY29tIiwicGFzc3dvcmQiOiJiJyQyYiQxMiR3UGFvand4QmtVUGxuZnB0RWtDVW1lSXVlVmxDblRFSHpXbFpjUnZnckJUb0J4clI0SEpuSyciLCJleHAiOjE2MTUyNjExNDV9.PYJRr78L765Ra4g2Vm3vxfGKw9f8yURZwiqF9iVJTEI'}, '/content/drive/MyDrive/Te/parsed/12/s12_en', 'gv', '/content/drive/MyDrive/Te/parsed/12/s12_en/gv.json')\n",
            "A_OGV-wGJKY-1615187332362\n",
            "{'count': 1, 'jobs': [{'active': True, 'input': {'files': [{'config': {'OCR': {'language': 'detect', 'option': 'HIGH_ACCURACY'}}, 'locale': 'en', 'path': 'fcb705ee-232f-4d63-b532-20eec1e89d32.pdf', 'type': 'PDF'}], 'workflowCode': 'WF_A_OGV'}, 'jobID': 'A_OGV-wGJKY-1615187332362', 'metadata': {'module': 'WORKFLOW-MANAGER', 'orgID': 'ANUVAAD', 'receivedAt': 1615187332362, 'requestID': 'a53275e2-8169-41ff-8c2f-9a73e79de294', 'sessionID': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyTmFtZSI6ImhhcnNoaXRhZGRAZ21haWwuY29tIiwicGFzc3dvcmQiOiJiJyQyYiQxMiR3UGFvand4QmtVUGxuZnB0RWtDVW1lSXVlVmxDblRFSHpXbFpjUnZnckJUb0J4clI0SEpuSyciLCJleHAiOjE2MTUyNjExNDV9.PYJRr78L765Ra4g2Vm3vxfGKw9f8yURZwiqF9iVJTEI', 'userID': '03e160d36bc34c8fb3a0fbb63e4b02701613729142248'}, 'startTime': 1615187332403, 'state': 'INITIATED', 'status': 'INPROGRESS', 'taskDetails': [], 'workflowCode': 'WF_A_OGV'}]}\n",
            "INPROGRESS\n",
            "COMPLETED\n",
            "0-16151873688068318.json\n",
            "A_OGV-wGJKY-1615187332362\n",
            "bulk search  response ************** 0-16151873688068318.json\n",
            "----------\n",
            "('A_OGV-hHuim-1615187336810', 'https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/jobs/search/bulk', {'auth-token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyTmFtZSI6ImhhcnNoaXRhZGRAZ21haWwuY29tIiwicGFzc3dvcmQiOiJiJyQyYiQxMiR3UGFvand4QmtVUGxuZnB0RWtDVW1lSXVlVmxDblRFSHpXbFpjUnZnckJUb0J4clI0SEpuSyciLCJleHAiOjE2MTUyNjExNDV9.PYJRr78L765Ra4g2Vm3vxfGKw9f8yURZwiqF9iVJTEI'}, '/content/drive/MyDrive/Te/parsed/12/s12_te', 'gv', '/content/drive/MyDrive/Te/parsed/12/s12_te/gv.json')\n",
            "A_OGV-hHuim-1615187336810\n",
            "{'count': 1, 'jobs': [{'active': True, 'input': {'files': [{'config': {'OCR': {'language': 'detect', 'option': 'HIGH_ACCURACY'}}, 'locale': 'en', 'path': '5e19ce0a-d643-4a34-bc0f-14c154b5a963.pdf', 'type': 'PDF'}], 'workflowCode': 'WF_A_OGV'}, 'jobID': 'A_OGV-hHuim-1615187336810', 'metadata': {'module': 'WORKFLOW-MANAGER', 'orgID': 'ANUVAAD', 'receivedAt': 1615187336810, 'requestID': 'f5bf46ef-cf5e-47d0-98db-ce1b71b8fa7d', 'sessionID': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyTmFtZSI6ImhhcnNoaXRhZGRAZ21haWwuY29tIiwicGFzc3dvcmQiOiJiJyQyYiQxMiR3UGFvand4QmtVUGxuZnB0RWtDVW1lSXVlVmxDblRFSHpXbFpjUnZnckJUb0J4clI0SEpuSyciLCJleHAiOjE2MTUyNjExNDV9.PYJRr78L765Ra4g2Vm3vxfGKw9f8yURZwiqF9iVJTEI', 'userID': '03e160d36bc34c8fb3a0fbb63e4b02701613729142248'}, 'startTime': 1615187336852, 'state': 'INITIATED', 'status': 'INPROGRESS', 'taskDetails': [], 'workflowCode': 'WF_A_OGV'}]}\n",
            "INPROGRESS\n",
            "COMPLETED\n",
            "0-16151874131515224.json\n",
            "A_OGV-hHuim-1615187336810\n",
            "bulk search  response ************** 0-16151874131515224.json\n",
            "----------------\n",
            "[('A_OGV-wGJKY-1615187332362', 'https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/jobs/search/bulk', {'auth-token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyTmFtZSI6ImhhcnNoaXRhZGRAZ21haWwuY29tIiwicGFzc3dvcmQiOiJiJyQyYiQxMiR3UGFvand4QmtVUGxuZnB0RWtDVW1lSXVlVmxDblRFSHpXbFpjUnZnckJUb0J4clI0SEpuSyciLCJleHAiOjE2MTUyNjExNDV9.PYJRr78L765Ra4g2Vm3vxfGKw9f8yURZwiqF9iVJTEI'}, '/content/drive/MyDrive/Te/parsed/12/s12_en', 'gv', '/content/drive/MyDrive/Te/parsed/12/s12_en/gv.json'), ('A_OGV-hHuim-1615187336810', 'https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/jobs/search/bulk', {'auth-token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyTmFtZSI6ImhhcnNoaXRhZGRAZ21haWwuY29tIiwicGFzc3dvcmQiOiJiJyQyYiQxMiR3UGFvand4QmtVUGxuZnB0RWtDVW1lSXVlVmxDblRFSHpXbFpjUnZnckJUb0J4clI0SEpuSyciLCJleHAiOjE2MTUyNjExNDV9.PYJRr78L765Ra4g2Vm3vxfGKw9f8yURZwiqF9iVJTEI'}, '/content/drive/MyDrive/Te/parsed/12/s12_te', 'gv', '/content/drive/MyDrive/Te/parsed/12/s12_te/gv.json')]\n",
            "----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('A_OGV-wGJKY-1615187332362',\n",
              "  'https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/jobs/search/bulk',\n",
              "  {'auth-token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyTmFtZSI6ImhhcnNoaXRhZGRAZ21haWwuY29tIiwicGFzc3dvcmQiOiJiJyQyYiQxMiR3UGFvand4QmtVUGxuZnB0RWtDVW1lSXVlVmxDblRFSHpXbFpjUnZnckJUb0J4clI0SEpuSyciLCJleHAiOjE2MTUyNjExNDV9.PYJRr78L765Ra4g2Vm3vxfGKw9f8yURZwiqF9iVJTEI'},\n",
              "  '/content/drive/MyDrive/Te/parsed/12/s12_en',\n",
              "  'gv',\n",
              "  '/content/drive/MyDrive/Te/parsed/12/s12_en/gv.json'),\n",
              " ('A_OGV-hHuim-1615187336810',\n",
              "  'https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/jobs/search/bulk',\n",
              "  {'auth-token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyTmFtZSI6ImhhcnNoaXRhZGRAZ21haWwuY29tIiwicGFzc3dvcmQiOiJiJyQyYiQxMiR3UGFvand4QmtVUGxuZnB0RWtDVW1lSXVlVmxDblRFSHpXbFpjUnZnckJUb0J4clI0SEpuSyciLCJleHAiOjE2MTUyNjExNDV9.PYJRr78L765Ra4g2Vm3vxfGKw9f8yURZwiqF9iVJTEI'},\n",
              "  '/content/drive/MyDrive/Te/parsed/12/s12_te',\n",
              "  'gv',\n",
              "  '/content/drive/MyDrive/Te/parsed/12/s12_te/gv.json')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO4uBcl0P6_P"
      },
      "source": [
        "#### Cleanup failed parses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKnGAulxAjY-"
      },
      "source": [
        "from collections import defaultdict \n",
        "\n",
        "present = defaultdict(lambda :0)\n",
        "for a in glob.glob(parsed_pdf_dir+\"/*/*/*\"):\n",
        "    b = a.split(\"/\")[-3]\n",
        "    present[b] = present[b]+1"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVIg_TZuAjY-"
      },
      "source": [
        "for key,value in present.items():\n",
        "    if value != 4:\n",
        "        print(key)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrUz-LnOAjY-"
      },
      "source": [
        "folders = []\n",
        "for a in glob.glob(parsed_pdf_dir+\"/*\"):\n",
        "    folders.append(a.split(\"/\")[-1])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjXO3bkUAjY_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd383300-c102-48a4-de30-96fffb68a153"
      },
      "source": [
        "set(folders).difference(present.keys())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EGZUQilP6_P"
      },
      "source": [
        "from collections import defaultdict \n",
        "\n",
        "present = defaultdict(lambda :0)\n",
        "for a in glob.glob(text_dir+\"/*/*\"):\n",
        "    b = a.split(\"/\")[-2]\n",
        "    present[b] = present[b]+1\n",
        "\n",
        "to_cleanup = []\n",
        "for key,value in present.items():\n",
        "    print(key,value)\n",
        "    if value != 2:\n",
        "        to_cleanup.append(key)\n",
        "        print(key)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WVNpyS1P6_Q"
      },
      "source": [
        "for a in glob.glob(text_dir+\"/*\"):\n",
        "    if any(i in a for i in to_cleanup):\n",
        "        shutil.rmtree(a)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLF9itpAP6_R"
      },
      "source": [
        "### Json to text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjGlSWFHwydm"
      },
      "source": [
        "total_parsed = len(glob.glob(parsed_pdf_dir + '/*/*'))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZi9lOBww3bw",
        "outputId": "1ecae84a-b259-406b-a5f6-98f2326b6a99"
      },
      "source": [
        "total_parsed"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-NQ-QVYAjY_"
      },
      "source": [
        "def extract_text(parent,folder_name):\n",
        "    with open(parsed_pdf_dir + f\"{parent}/{folder_name}/gv.json\",'r') as f:\n",
        "        data = json.load(f)\n",
        "    pages = data['outputs'][0]['pages']\n",
        "    all_texts = []\n",
        "    for page in pages:\n",
        "        page_text = []\n",
        "        lines = page['lines']\n",
        "        for line in lines:\n",
        "            page_text.append(line['text'])\n",
        "        all_texts.append(page_text)\n",
        "    all_lines = [line for al in all_texts for line in al]\n",
        "    all_text = \" \".join(all_lines)\n",
        "    lang = folder_name[-2:]\n",
        "    os.system('mkdir -p \"{}\"'.format(text_dir + f\"{parent}\"))\n",
        "    with open(text_dir + f\"{parent}/{folder_name}.txt\",'w',encoding='utf-16') as f:\n",
        "        f.writelines(all_text)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lafpoAzsAjY_"
      },
      "source": [
        "import glob\n",
        "import shutil\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "failed_parses = []\n",
        "for name in glob.glob(parsed_pdf_dir + '/*/*'):\n",
        "    folder_name = name.replace(parsed_pdf_dir,\"\")\n",
        "    parent ,  folder_name = folder_name.split(\"/\")\n",
        "    try:\n",
        "        extract_text(parent,folder_name)\n",
        "    except:\n",
        "        print(folder_name)\n",
        "        failed_parses.append(folder_name)\n",
        "        \n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw5v9_WAwRB4"
      },
      "source": [
        "for folder_name in failed_parses:\r\n",
        "    dirpath = Path(text_dir + f\"{folder_name}\")\r\n",
        "    if dirpath.exists():\r\n",
        "        shutil.rmtree(dirpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08-XdszmAjZA"
      },
      "source": [
        "#### Cleanup failed pdf to text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkKESzkCAjZA"
      },
      "source": [
        "from collections import defaultdict \n",
        "\n",
        "present = defaultdict(lambda :0)\n",
        "for a in glob.glob(text_dir+\"/*/*\"):\n",
        "    b = a.split(\"/\")[-2]\n",
        "    present[b] = present[b]+1\n",
        "\n",
        "to_cleanup = []\n",
        "for key,value in present.items():\n",
        "    if value != 2:\n",
        "        to_cleanup.append(key)\n",
        "        print(key)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikt8TiqrAjZA"
      },
      "source": [
        "for a in glob.glob(text_dir+\"/*\"):\n",
        "    if any(i in a for i in to_cleanup):\n",
        "        shutil.rmtree(a)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9On4JfwmP6_S"
      },
      "source": [
        "### Sentence Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N00gfch2P6_S"
      },
      "source": [
        "def upload_file(file):\n",
        "    url = 'https://auth.anuvaad.org/anuvaad-api/file-uploader/v0/upload-file'\n",
        "    files = [('file',(open(file,'rb')))] \n",
        "    response = requests.post(url, headers=headers, files=files)\n",
        "    print(response.json())\n",
        "    return response.json()['data']\n",
        "\n",
        "\n",
        "def add_tokenize_job(file_path,lang):\n",
        "    body = {\n",
        "            \"workflowCode\": \"WF_A_TOK\",\n",
        "            \"jobName\": \"TOKENIZE_WF_TEST\",\n",
        "            \"files\": [\n",
        "                {\n",
        "                    \"locale\":  lang,\n",
        "                    \"path\": file_path,\n",
        "                    \"type\": \"txt\"\n",
        "                }]}\n",
        "    url = \"https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/async/initiate\"\n",
        "    response = requests.post(url, headers=headers,json=body).json()\n",
        "    print(response)\n",
        "    return response['jobID']\n",
        "\n",
        "def bulk_search_tokenize(job_id,bs_url,headers):\n",
        "    bs_request = {\n",
        "    \"jobIDs\": [job_id],\n",
        "    \"taskDetails\":\"true\"}\n",
        "    print(job_id)\n",
        "    res = requests.post(bs_url,json=bs_request,headers=headers, timeout = 10000)\n",
        "\n",
        "    prev_progress = \"\"\n",
        "    \n",
        "    while(1):\n",
        "      progress = res.json()['jobs'][0]['status']\n",
        "      if progress in ['COMPLETED','FAILED','FINISHED','SUCCESS']:\n",
        "          data = res.json()\n",
        "          outputfile = res.json()['jobs'][0]['taskDetails'][0]['output'][0]['outputFile']\n",
        "          print(data['jobs'][0]['output'])\n",
        "          return outputfile\n",
        "          break \n",
        "      sleep(1)\n",
        "      if progress != prev_progress:\n",
        "          print(progress)\n",
        "          prev_progress = progress\n",
        "      res = requests.post(bs_url,json=bs_request,headers=headers, timeout = 10000)\n",
        "\n",
        "\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBeebXhNYolS",
        "outputId": "bf05413e-f82d-462d-c892-2018fd2aa6c4"
      },
      "source": [
        "jobs_to_track = []\r\n",
        "folder = sentences_dir\r\n",
        "for file in glob.glob(text_dir+\"/*/*\"):\r\n",
        "    print(file)\r\n",
        "    upload_file(file)\r\n",
        "    lang = file.split('.')[0][-2:]\r\n",
        "    job_id = add_tokenize_job(file,lang)\r\n",
        "    jobs_to_track.append((job_id,folder.split(\"/\")[-1]))\r\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Te/text/12/s12_en.txt\n",
            "{'data': '9d44b7b8-7474-4afb-a98c-2d2801d05905.txt', 'http': {'status': 200}, 'ok': True, 'why': 'request successful'}\n",
            "{'active': True, 'input': {'files': [{'locale': 'en', 'path': '/content/drive/MyDrive/Te/text/12/s12_en.txt', 'type': 'txt'}], 'jobName': 'TOKENIZE_WF_TEST', 'workflowCode': 'WF_A_TOK'}, 'jobID': 'A_TK-EOHMK-1615189279842', 'metadata': {'module': 'WORKFLOW-MANAGER', 'orgID': 'ANUVAAD', 'receivedAt': 1615189279842, 'requestID': '83332f85-f5db-401e-a550-3c12df43e884', 'sessionID': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyTmFtZSI6ImhhcnNoaXRhZGRAZ21haWwuY29tIiwicGFzc3dvcmQiOiJiJyQyYiQxMiR3UGFvand4QmtVUGxuZnB0RWtDVW1lSXVlVmxDblRFSHpXbFpjUnZnckJUb0J4clI0SEpuSyciLCJleHAiOjE2MTUyNjExNDV9.PYJRr78L765Ra4g2Vm3vxfGKw9f8yURZwiqF9iVJTEI', 'userID': '03e160d36bc34c8fb3a0fbb63e4b02701613729142248'}, 'startTime': 1615189279883, 'state': 'INITIATED', 'status': 'STARTED', 'taskDetails': [], 'workflowCode': 'WF_A_TOK'}\n",
            "/content/drive/MyDrive/Te/text/12/s12_te.txt\n",
            "{'data': '1a7e5934-3034-4bda-881c-f516eefeccad.txt', 'http': {'status': 200}, 'ok': True, 'why': 'request successful'}\n",
            "{'active': True, 'input': {'files': [{'locale': 'te', 'path': '/content/drive/MyDrive/Te/text/12/s12_te.txt', 'type': 'txt'}], 'jobName': 'TOKENIZE_WF_TEST', 'workflowCode': 'WF_A_TOK'}, 'jobID': 'A_TK-LKwAe-1615189284075', 'metadata': {'module': 'WORKFLOW-MANAGER', 'orgID': 'ANUVAAD', 'receivedAt': 1615189284075, 'requestID': '4893e956-4191-4e8d-9807-e07291586c74', 'sessionID': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyTmFtZSI6ImhhcnNoaXRhZGRAZ21haWwuY29tIiwicGFzc3dvcmQiOiJiJyQyYiQxMiR3UGFvand4QmtVUGxuZnB0RWtDVW1lSXVlVmxDblRFSHpXbFpjUnZnckJUb0J4clI0SEpuSyciLCJleHAiOjE2MTUyNjExNDV9.PYJRr78L765Ra4g2Vm3vxfGKw9f8yURZwiqF9iVJTEI', 'userID': '03e160d36bc34c8fb3a0fbb63e4b02701613729142248'}, 'startTime': 1615189284119, 'state': 'INITIATED', 'status': 'STARTED', 'taskDetails': [], 'workflowCode': 'WF_A_TOK'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGurarHnYRhO"
      },
      "source": [
        "def download_file(outputfile):\r\n",
        "\r\n",
        "    download_url =\"https://auth.anuvaad.org/download/\"+str(outputfile)\r\n",
        "    res = requests.get(download_url,headers=headers)\r\n",
        "    return res.content"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ1Kkc0FYT7k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "150ee7b4-f046-4a5d-f67d-7d19f6f73ad4"
      },
      "source": [
        "for job_id, folder in jobs_to_track:\r\n",
        "    file_to_download = bulk_search_tokenize(job_id,bs_url,headers)\r\n",
        "    print(file_to_download)\r\n",
        "    for key , value in file_to_download.items():\r\n",
        "        content = download_file(value)\r\n",
        "        os.system('mkdir -p \"{}\"'.format(sentences_path+folder))\r\n",
        "        with open(os.path.join(test_sentences_path,folder,f\"{key}.text\"),'w',encoding=\"utf-16\") as f:\r\n",
        "            f.writelines(content.decode('utf-16'))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A_TK-EOHMK-1615189279842\n",
            "INPROGRESS\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-8fd713ee8aaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs_to_track\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfile_to_download\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbulk_search_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_to_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_to_download\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-d2f2a4554a53>\u001b[0m in \u001b[0;36mbulk_search_tokenize\u001b[0;34m(job_id, bs_url, headers)\u001b[0m\n\u001b[1;32m     39\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0moutputfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mprogress\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mprev_progress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GQwmvQyP6_S",
        "scrolled": true
      },
      "source": [
        "failed_files = []\n",
        "for file in glob.glob(text_dir+ \"*/*.txt\"):  \n",
        "    lang = file.split(\".txt\")[0].split(\"_\")[-1]\n",
        "    print(lang)\n",
        "    file_path = upload_file(file)\n",
        "    tokenized_file_id = tokenize_text(file_path,lang)\n",
        "    print('Tokenized file id ', tokenized_file_id)\n",
        "    if tokenized_file_id:\n",
        "        content = download_file(tokenized_file_id)\n",
        "        os.system('mkdir -p \"{}\"'.format(sentences_dir+ file.split(\"/\")[-2]))\n",
        "        write_path = sentences_dir+ file.split(\"/\")[-2] + \"/\" + file.split(\"/\")[-1]\n",
        "        with open(write_path,'w',encoding=\"utf-16\") as f:\n",
        "            f.writelines(content.decode('utf-16'))\n",
        "    else:\n",
        "        failed_files.append((file_path,lang))\n",
        "failed_files_again = []\n",
        "for file_path,lang in failed_files:\n",
        "    tokenized_file_id = tokenize_text(file_path,lang)\n",
        "    if tokenized_file_id:\n",
        "        content = download_file(tokenized_file_id)\n",
        "        os.system('mkdir -p \"{}\"'.format(sentences_dir+ file.split(\"/\")[-2]))\n",
        "        write_path = sentences_dir+ file.split(\"/\")[-2] + \"/\" + file.split(\"/\")[-1]\n",
        "        with open(write_path,'w',encoding=\"utf-16\") as f:\n",
        "            f.writelines(content.decode('utf-16'))\n",
        "    else:\n",
        "        failed_files_again.append((file_path,lang))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXWiWOmO2XYq"
      },
      "source": [
        "print(len(failed_files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zGTgEPYP6_T"
      },
      "source": [
        "#### Clean up failed setence segmentation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMCFC3f4P6_T"
      },
      "source": [
        "from collections import defaultdict \n",
        "\n",
        "present = defaultdict(lambda :0)\n",
        "for a in glob.glob(sentences_dir+\"/*/*\"):\n",
        "    b = a.split(\"/\")[-2]\n",
        "    present[b] = present[b]+1\n",
        "\n",
        "to_cleanup = []\n",
        "for key,value in present.items():\n",
        "#     print(key,value)\n",
        "    if value != 2:\n",
        "        to_cleanup.append(key)\n",
        "        print(key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bRbAZv8P6_T"
      },
      "source": [
        "for a in glob.glob(sentences_dir+\"/*\"):\n",
        "    if any(i in a for i in to_cleanup):\n",
        "        shutil.rmtree(a)\n",
        "#         print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akDZv_wWP6_T"
      },
      "source": [
        "### Sentence Alignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgd2kTpNP6_T"
      },
      "source": [
        "upload_url = \"https://auth.anuvaad.org/anuvaad-api/file-uploader/v0/upload-file\"\n",
        "aligner_url = \"https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/async/initiate\"\n",
        "download_url = \"https://auth.anuvaad.org/download/\"\n",
        "search_url = \"'https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/jobs/search/bulk'\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgKxr-rBP6_T",
        "scrolled": true
      },
      "source": [
        "def bulk_search_alignment(job_id,bs_url,headers):\n",
        "    bs_request = {\n",
        "    \"jobIDs\": [job_id],\n",
        "    \"taskDetails\":\"true\"\n",
        "    }\n",
        "    print(job_id)\n",
        "    res = requests.post(bs_url,json=bs_request,headers=headers, timeout = 10000)\n",
        "    prev_progress = \"\"\n",
        "   \n",
        "    while(1):\n",
        "\n",
        "        progress = res.json()['jobs'][0]['status']\n",
        "      \n",
        "        if progress in ['COMPLETED','FAILED']:\n",
        "            print(progress)\n",
        "            data = res.json()\n",
        "            secondlanguage = data['jobs'][0]['input']['files'][0]['locale']    \n",
        "            print(secondlanguage)\n",
        "            source , target = \"source\" , \"target\"\n",
        "            if secondlanguage == 'en.txt':\n",
        "                source , target = target, source\n",
        "            nomatch=str(data['jobs'][0]['output']['noMatch']['source'])\n",
        "            match_english=str(data['jobs'][0][\"output\"]['match'][target])\n",
        "            match_non_english=str(data['jobs'][0][\"output\"]['match'][source])\n",
        "            almostmatch_english=str(data['jobs'][0]['output']['almostMatch'][target])\n",
        "            almostatch_non_english=str(data['jobs'][0]['output']['almostMatch'][source])\n",
        "            return {\n",
        "                'match_english' : match_english,\n",
        "                'match_non_english' : match_non_english,\n",
        "                'almost_match_english' : almostmatch_english,\n",
        "                'almost_non_match_english' : almostatch_non_english,\n",
        "                'no_match' : nomatch}\n",
        "            break\n",
        "        sleep(0.5)\n",
        "        if progress != prev_progress:\n",
        "            print(progress)\n",
        "            prev_progress = progress\n",
        "        res = requests.post(bs_url,json=bs_request,headers=headers, timeout = 10000)\n",
        "        #print(res.json())\n",
        "      \n",
        "\n",
        "def upload_files(folder):\n",
        "    path_lang_tup = []\n",
        "    for file in glob.glob(folder+\"/*\"):\n",
        "        print(file)\n",
        "        lang = file.split(\"_\")[-1]        \n",
        "        path_lang_tup.append((upload_file(file),lang))\n",
        "    return path_lang_tup\n",
        "\n",
        "def submit_alignment_job(path_lang_tup):\n",
        "    print(path_lang_tup)\n",
        "    files = []\n",
        "    for path, lang in path_lang_tup:\n",
        "        files.append({\n",
        "                        \"locale\": lang,\n",
        "                        \"path\": path,\n",
        "                        \"type\": \"txt\"\n",
        "                    })\n",
        "    \n",
        "    \n",
        "    aligner_body = {\n",
        "        \"workflowCode\":\"WF_A_AL\",\n",
        "        \"files\": files}\n",
        "    \n",
        "    aligner_response = requests.request(\"POST\", aligner_url, json=aligner_body, headers=headers).json()\n",
        "    return aligner_response['jobID']\n",
        "    \n",
        "jobs_to_track = []\n",
        "for folder in glob.glob(sentences_dir+\"/*\"):\n",
        "    print(folder)\n",
        "    path_lang_tup = upload_files(folder)\n",
        "    job_id = submit_alignment_job(path_lang_tup)\n",
        "    jobs_to_track.append((job_id,folder.split(\"/\")[-1]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ0rFzE3P6_U",
        "scrolled": true
      },
      "source": [
        "\n",
        "for job_id, folder in jobs_to_track:\n",
        "    file_to_download = bulk_search_alignment(job_id,bs_url,headers)\n",
        "    for key , value in file_to_download.items():\n",
        "        content = download_file(value)\n",
        "        os.system('mkdir -p \"{}\"'.format(aligned_sentences_path+folder))\n",
        "        with open(os.path.join(aligned_sentences_path,folder,f\"{key}.text\"),'w',encoding=\"utf-16\") as f:\n",
        "            f.writelines(content.decode('utf-16'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twRv1icrP6_U"
      },
      "source": [
        "from collections import defaultdict \n",
        "\n",
        "present = defaultdict(lambda :0)\n",
        "for a in glob.glob(aligned_sentences_path+\"/*/*\"):\n",
        "    b = a.split(\"/\")[-2]\n",
        "    present[b] = present[b]+1\n",
        "\n",
        "to_cleanup = []\n",
        "for key,value in present.items():\n",
        "#     print(key,value)\n",
        "    if value != 5:\n",
        "        to_cleanup.append(key)\n",
        "        print(key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKoPg3VwP6_U"
      },
      "source": [
        "to_cleanup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYMkY1btP6_U"
      },
      "source": [
        "### Aligned Sentences to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0CWhibjP6_U"
      },
      "source": [
        "import pandas as pd\n",
        "match_dfs = []\n",
        "almost_match_dfs = []\n",
        "for a in glob.glob(aligned_sentences_path+\"/*\"):\n",
        "    match = pd.DataFrame()\n",
        "    with open(a + \"/\" + \"match_english.text\",encoding='utf-16') as f:\n",
        "        match['english'] = f.readlines()\n",
        "    with open(a + \"/\" + \"match_non_english.text\",encoding='utf-16') as f:\n",
        "        match['non_english'] = f.readlines()\n",
        "    match_dfs.append(match)\n",
        "    almost_match = pd.DataFrame()\n",
        "    with open(a + \"/\" + \"almost_match_english.text\",encoding='utf-16') as f:\n",
        "        almost_match['english'] = f.readlines()\n",
        "    with open(a + \"/\" + \"almost_non_match_english.text\",encoding='utf-16') as f:\n",
        "        almost_match['non_english'] = f.readlines()\n",
        "    match_dfs.append(match)\n",
        "    almost_match_dfs.append(almost_match)\n",
        "\n",
        "match = pd.concat(match_dfs)\n",
        "almost_match = pd.concat(almost_match_dfs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A0nsCVFP6_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "872ed9ae-eab3-4715-a1be-dd41c793890b"
      },
      "source": [
        "len(match)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1418"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT7UfJFoP6_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67122b63-edd0-45bd-fa1d-74ba29ed626b"
      },
      "source": [
        "len(almost_match)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "224"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJNqh6uVP6_V"
      },
      "source": [
        "match.to_csv(parent_folder + \"match.csv\")\n",
        "almost_match.to_csv(parent_folder + \"almost_match.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ-m-STZ2xFk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}