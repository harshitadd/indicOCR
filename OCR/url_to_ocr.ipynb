{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "urlPDF2TXT_with_sentence_splitting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYFFB7MVv4ULFgJeX5rr0Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitadd/AI4BharatTranslation/blob/main/urlPDF2TXT_with_sentence_splitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-N9iAjHXMU-"
      },
      "source": [
        "!sudo apt install tesseract-ocr\r\n",
        "!apt-get install poppler-utils\r\n",
        "!pip install indic-nlp-library\r\n",
        "!pip install pytesseract\r\n",
        "!pip install sentence-splitter\r\n",
        "!pip install pdf2image\r\n",
        "!pip install sentence_transformers\r\n",
        "\r\n",
        "# UPLOAD TRAINDATA FILE # at /usr/share/tesseract-ocr/4.00/tessdata/tam.traineddata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf3rS84hW1Sn"
      },
      "source": [
        "import requests\r\n",
        "from PIL import Image \r\n",
        "import pytesseract \r\n",
        "import sys \r\n",
        "from pdf2image import convert_from_path \r\n",
        "import os\r\n",
        "import sys\r\n",
        "from indicnlp.tokenize import indic_tokenize\r\n",
        "from indicnlp.tokenize import sentence_tokenize \r\n",
        "from sentence_transformers import SentenceTransformer\r\n",
        "import numpy as np\r\n",
        "import re \r\n",
        "from sentence_splitter import SentenceSplitter, split_text_into_sentences\r\n",
        "from scipy.spatial import distance\r\n",
        "pytesseract.pytesseract.tesseract_cmd = (r'/usr/bin/tesseract')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZEVhyXCIOoR",
        "outputId": "729ea214-1144-410a-82a7-b4937773f60d"
      },
      "source": [
        "# Data Source \r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive') # CHANGE THIS "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yJ4MoP4Zc2m"
      },
      "source": [
        "def source_links():\r\n",
        "  with open('/content/gdrive/MyDrive/source_links.txt','r') as file: \r\n",
        "    links = file.read()                                              # l [0] ==> eng link and l[1] ==> tam link \r\n",
        "    links = links.split()\r\n",
        "    source_links = []\r\n",
        "    for link in links:\r\n",
        "      if '_e_' in link:\r\n",
        "        l = []\r\n",
        "        l.append(link)\r\n",
        "        temp = link \r\n",
        "        temp = temp.replace('_e_','_t_')\r\n",
        "        l.append(temp)\r\n",
        "        source_links.append(l)\r\n",
        "    print('Number of Source Links :' + str(len(source_links)))\r\n",
        "  return source_links"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mBW__GwsXqp"
      },
      "source": [
        "\r\n",
        "batched_links = []\r\n",
        "# Making Mini Batches for download+preprocess\r\n",
        "def minibatch(source_links):\r\n",
        "  for j in range(0, len(source_links),20):\r\n",
        "    batched_links.append(source_links[j:j+20])\r\n",
        "  return batched_links \r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Het4jGbBon8z"
      },
      "source": [
        "def download_pdf_to_image(prim_lid, sec_lid, source_links, batch_index):\r\n",
        "  source_counter = 1\r\n",
        "  failed = []\r\n",
        "  for source in source_links:\r\n",
        "    eng = source[0]\r\n",
        "    tam = source[1]\r\n",
        "    response_eng = requests.get(eng)\r\n",
        "    response_tam = requests.get(tam) \r\n",
        "    en = '/content/gdrive/MyDrive/eng' + '_' + str(batch_index) + '_' + str(source_counter) + '.pdf'\r\n",
        "    ta = '/content/gdrive/MyDrive/tam' + '_' + str(batch_index) + '_' + str(source_counter) + '.pdf'\r\n",
        "    try:\r\n",
        "      with open(en, 'wb') as e, open(ta, 'wb') as t:\r\n",
        "          e.write(response_eng.content)\r\n",
        "          t.write(response_tam.content)   \r\n",
        "          pages = convert_from_path(en, 200) \r\n",
        "          image_counter = 1\r\n",
        "          for page in pages: \r\n",
        "            filename = \"page_\"+str(image_counter)+\".jpg\"\r\n",
        "            page.save(filename, 'JPEG') \r\n",
        "            image_counter = image_counter + 1\r\n",
        "          filelimit = image_counter-1\r\n",
        "          print('English version of ' + str(source_counter) + ' PDF Succesfully Saved as Images')\r\n",
        "          outfile = '/content/gdrive/MyDrive/eng' + '_' + str(batch_index) + '_' + str(source_counter) + '.txt' \r\n",
        "          f = open(outfile, \"a\") \r\n",
        "          content = ''\r\n",
        "          for i in range(1, filelimit + 1):\r\n",
        "            filename = \"page_\"+str(i)+\".jpg\" \r\n",
        "            try: \r\n",
        "              content += str(((pytesseract.image_to_string(Image.open(filename),lang='eng+tam'))))  \r\n",
        "            except:\r\n",
        "              content +=' '\r\n",
        "          content = content.replace('\\n',' ')\r\n",
        "          splitter = SentenceSplitter(language='en')\r\n",
        "          so_sentences = splitter.split(content)\r\n",
        "          text = ''\r\n",
        "          for s in so_sentences:\r\n",
        "            text += s\r\n",
        "            text += '\\n'\r\n",
        "          f.write(text)\r\n",
        "          f.close() \r\n",
        "          print(' English PDF Processed Completely')\r\n",
        "\r\n",
        "\r\n",
        "          # Working on Tamil   \r\n",
        "          pages = convert_from_path(ta, 200) \r\n",
        "          image_counter = 1\r\n",
        "          skipped = 0\r\n",
        "          for page in pages: \r\n",
        "            filename = \"page_\"+str(image_counter)+\".jpg\"\r\n",
        "            page.save(filename, 'JPEG') \r\n",
        "            image_counter = image_counter + 1\r\n",
        "          filelimit = image_counter-1\r\n",
        "          print('Tamil version of ' + str(source_counter) + ' PDF Succesfully Saved as Images')\r\n",
        "\r\n",
        "          outfile = '/content/gdrive/MyDrive/tam' + '_' + str(batch_index) + '_' + str(source_counter) + '.txt' \r\n",
        "          f = open(outfile, \"a\") \r\n",
        "          content = ''\r\n",
        "          for i in range(1, filelimit + 1):\r\n",
        "            filename = \"page_\"+str(i)+\".jpg\" \r\n",
        "            try: \r\n",
        "              content += str(((pytesseract.image_to_string(Image.open(filename),lang='tam+eng'))))  \r\n",
        "            except:\r\n",
        "              content +=' '\r\n",
        "          content = content.replace('\\n',' ')\r\n",
        "          ta_sentences = sentence_tokenize.sentence_split(content, lang='ta') \r\n",
        "          text = ''\r\n",
        "          for s in ta_sentences:\r\n",
        "            text += s\r\n",
        "            text += '\\n'\r\n",
        "          f.write(text)\r\n",
        "          f.close() \r\n",
        "          print('Tamil PDF Processed Completely')\r\n",
        "          source_counter+=1\r\n",
        "    except: \r\n",
        "          failed.append((eng,tam))   \r\n",
        "          print('Failed for ' + str(source_counter) + 'PDF' )   \r\n",
        "    \r\n",
        "  print('Batch Complete!')\r\n",
        "  print('Total Number of Documents was ' + str(len(source_links)))\r\n",
        "  print('URL fetch failed for :' + str(len(failed)))\r\n",
        "  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM7JoW1FUdh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a44d95-1dae-47aa-cbfc-17458cd4ccc0"
      },
      "source": [
        "# CHANGE THIS\r\n",
        "source_links = source_links() \r\n",
        "prim_lid = 'tam' # Primary lang\r\n",
        "sec_lid = 'eng' # Depending upon which language is codeswitched.\r\n",
        "batch_index = 6 # Change for different batches \r\n",
        "# # # \r\n",
        "\r\n",
        "batched_links = minibatch(source_links)\r\n",
        "download_pdf_to_image(prim_lid, sec_lid, batched_links[batch_index], batch_index) # Downloading PDFs and storing them on Gdrive\r\n",
        "print('Post Processing Complete for : ' + str(batch_index) + ' Batch Number')\r\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Source Links :431\n",
            "English version of 1 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 1 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 2 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 2 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 3 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 3 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 4 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 4 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 5 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 5 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 6 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 6 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 7 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 7 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 8 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 8 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 9 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 9 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 10 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 10 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 11 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 11 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 12 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 12 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 13 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 13 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 14 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Failed for 14PDF\n",
            "English version of 14 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 14 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 15 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 15 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 16 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 16 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 17 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 17 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 18 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Tamil version of 18 PDF Succesfully Saved as Images\n",
            "Tamil PDF Processed Completely\n",
            "English version of 19 PDF Succesfully Saved as Images\n",
            " English PDF Processed Completely\n",
            "Failed for 19PDF\n",
            "Batch Complete!\n",
            "Total Number of Documents was 20\n",
            "URL fetch failed for :2\n",
            "Post Processing Complete for : 6 Batch Number\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf6ghgzJYz2G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}