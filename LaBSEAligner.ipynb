{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LaBSEAligner.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP7ryDL53hVjCDOk0zcCVmk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitadd/AI4BharatTranslation/blob/main/LaBSEAligner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_SRarMhD5TD"
      },
      "source": [
        "!pip install sentence_transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJLyAZjGEAiv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "999b9b3b-a5c2-4344-92ef-0e54e060b651"
      },
      "source": [
        "!pip install scipy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BquFyh66EZeW"
      },
      "source": [
        "!pip install indic-nlp-library"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AiW7zbjAWiO",
        "outputId": "4cbdc3f3-c36c-4169-fae4-599fe3b887ce"
      },
      "source": [
        "import sys\n",
        "from indicnlp.tokenize import indic_tokenize\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from scipy.spatial import distance\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/LaBSE\")\n",
        "# model = AutoModel.from_pretrained(\"sentence-transformers/LaBSE\")\n",
        "model = SentenceTransformer('LaBSE')\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.75G/1.75G [00:30<00:00, 58.0MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFYvD8axb5xW",
        "outputId": "a91ff321-176b-463e-ae70-0660e780c3f4"
      },
      "source": [
        "!pip install sentence-splitter"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-splitter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/ae/3bd609c760d57849d7ddf223762f1881f3c4df6467f4eadb3a33652b7e0d/sentence_splitter-1.4-py2.py3-none-any.whl (44kB)\n",
            "\r\u001b[K     |███████▎                        | 10kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 20kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 30kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 40kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex>=2017.12.12 in /usr/local/lib/python3.6/dist-packages (from sentence-splitter) (2019.12.20)\n",
            "Installing collected packages: sentence-splitter\n",
            "Successfully installed sentence-splitter-1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2KL7hEucGfE",
        "outputId": "10e7f3e6-bc45-4dd0-82b4-5db659e84457"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D1USqNgcM-4"
      },
      "source": [
        "with open('/content/drive/MyDrive/eng_2.txt','r') as file:\r\n",
        "  content = file.read()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81NNA7PVb3gX"
      },
      "source": [
        "# Only for English\r\n",
        "import re \r\n",
        "from sentence_splitter import SentenceSplitter, split_text_into_sentences\r\n",
        "content = content.replace('\\n',' ')\r\n",
        "splitter = SentenceSplitter(language='en')\r\n",
        "sentences = splitter.split(content)\r\n",
        "\r\n",
        "# final = ''\r\n",
        "# for s in sentences:\r\n",
        "# \tfinal+=s\r\n",
        "# \tfinal+='\\n'\r\n",
        "# sentence_count=len(sentences)\r\n",
        "# print(sentence_count)\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvFG4sRyipuC",
        "outputId": "b0dc0ffb-8e78-467d-9b23-4d7d3efc6e4b"
      },
      "source": [
        "len(sentences)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "813"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BNbn3WPit5r"
      },
      "source": [
        "temp = sentences[0:20]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sslng8IDDsDF"
      },
      "source": [
        "def phrase_aligner(src, tgtp):\n",
        "      '''\n",
        "      This function is meant to align src phrases with best possible tgt phrase using LABSE model\n",
        "      '''\n",
        "      out = {}\n",
        "      aligned_phrases = {}\n",
        "      print(\"Performing phrase alignenment using LABSE\")\n",
        "      print(src,tgtp)\n",
        "      src_phrases, tgt = src, tgtp\n",
        "      \n",
        "      for src_phrase in src_phrases:\n",
        "          length_src_phrase = len(src_phrase.split())           \n",
        "          tgt_token_list = split_tgt(length_src_phrase,tgt)\n",
        "          embeddings_src_phrase, embeddings_tgt_tokens = generate_embeddings([src_phrase],tgt_token_list)\n",
        "          alignments = get_target_sentence(embeddings_tgt_tokens, embeddings_src_phrase, length_src_phrase)\n",
        "      \n",
        "          if alignments is not None and alignments[2] is \"MATCH\":\n",
        "              aligned_phrases[src_phrase] = tgt_token_list[alignments[0]]\n",
        "          elif alignments is not None and alignments[2] is \"NOMATCH\": \n",
        "              print(\"No exact match found for:{} . Possible alignment {}\".format(src_phrase,tgt_token_list[alignments[0]]))  \n",
        "                      \n",
        "      print(\"Aligned Phrases: {}\".format(aligned_phrases))\n",
        "      out = {\"tgt\":tgt,\"src_phrases\":src_phrases,\"aligned_phrases\":aligned_phrases}     \n",
        "\n",
        "      return out\n",
        "\n",
        "def split_tgt(length_src_phrase,tgt):\n",
        "  tgt_token_list = list()\n",
        "  tokenised_tgt = tgt.split()\n",
        "  tgt_token_list = [tokenised_tgt[i:i+length_src_phrase] for i in range(len(tokenised_tgt)) if (i + length_src_phrase) <= len(tokenised_tgt)]\n",
        "  tgt_token_list_plus = [tokenised_tgt[i:i+length_src_phrase+1] for i in range(len(tokenised_tgt)) if (i + length_src_phrase+1) <= len(tokenised_tgt)]\n",
        "  tgt_token_list_minus = [tokenised_tgt[i:i+length_src_phrase-1] for i in range(len(tokenised_tgt)) if (i + length_src_phrase-1) <= len(tokenised_tgt) and \n",
        "                          length_src_phrase != 1]\n",
        "  tgt_token_list = tgt_token_list + tgt_token_list_plus + tgt_token_list_minus\n",
        "  tgt_token_list = [\" \".join(j) for j in tgt_token_list]\n",
        "  return tgt_token_list\n",
        "      \n",
        "def generate_embeddings(input_1, input_2):\n",
        "  '''\n",
        "  Generate LABSE embeddings\n",
        "  Note: Inputs are array of strings\n",
        "  '''           \n",
        "  embeddings_input_1 = model.encode(input_1,show_progress_bar=True)\n",
        "  embeddings_input_2 = model.encode(input_2,show_progress_bar=True)    \n",
        "  print(\"LABSE embedding generation finished\")\n",
        "  return embeddings_input_1, embeddings_input_2\n",
        "  \n",
        "def get_target_sentence(target_embeddings, source_embedding, length_src_phrase):\n",
        "  '''\n",
        "  Calculate cosine similarity using scipy distance method\n",
        "  '''\n",
        "  distances = distance.cdist(source_embedding, target_embeddings, \"cosine\")[0]\n",
        "  min_index = np.argmin(distances)\n",
        "  min_distance = 1 - distances[min_index]\n",
        "  print(\"Match score: {}\".format(min_distance))\n",
        "  if min_distance >= 0.5:\n",
        "      return min_index, min_distance, \"MATCH\"\n",
        "  else:\n",
        "      return min_index, min_distance, \"NOMATCH\"     \n",
        "      \n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMhIUCV8i3s1"
      },
      "source": [
        "print(content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YReBoIx5jGL0"
      },
      "source": [
        "tgtp = '''ஆன்மாவின்‌ முன்‌ தலைவணங்கி, 2018-2019 ஆம்‌ ஆண்டிற்கான\r\n",
        "நிதிநிலை அறிக்கையை இந்தப்‌ பேரவையின்‌ முன்‌ சமர்ப்பிக்க\r\n",
        "விழைகிறேன்‌.\r\n",
        "\r\n",
        "2. மக்களின்‌ உள்ளங்களில்‌ நீங்கா இடம்‌ பெற்று, அவர்களின்‌\r\n",
        "பேரன்பைப்‌ பெற்ற மாபெரும்‌ தலைவியாக விளங்கிய புரட்சித்‌ தலைவி\r\n",
        "அம்மா அவர்கள்‌ தொடங்கி வைத்த அனைத்து திட்டங்களையும்‌\r\n",
        "தொடர்ந்து செயல்படுத்துவதில்‌ இந்த அரசு உறுதியாக உள்ளது.\r\n",
        "தொலைநோக்குப்‌ பார்வையும்‌, மதிநுட்பமும்‌ வாய்ந்த புரட்சித்‌ தலைவி\r\n",
        "அம்மா அவர்களின்‌ “அமைதி, வளம்‌, வளர்ச்சி! என்ற கொள்கை முழக்கம்‌,\r\n",
        "இந்த மாநிலத்தை முன்னேற்றப்‌ பாதையில்‌ கொண்டு செல்வதற்கான\r\n",
        "வழிகாட்டும்‌ அடிப்படை கொள்கையாக தொடர்ந்து விளங்கும்‌. பொது\r\n",
        "சுகாதாரம்‌, கல்வி, சமூகப்‌ பாதுகாப்பு போன்ற துறைகளில்‌\r\n",
        "செயல்படுத்தப்பட்டு வரும்‌ பல்வேறு திட்டங்கள்‌, நமது மாநிலத்தின்‌\r\n",
        "மனிதவள மேம்பாட்டுக்‌ குறியீடுகளை உயர்த்தி, நாட்டிலேயே\r\n",
        "சமூகநலத்தைப்‌ பேணிப்‌ போற்றும்‌ முன்மாதிரி மாநிலமாகத்‌ தமிழ்நாட்டை\r\n",
        "உருவாக்கியுள்ளது என்பதை யாராலும்‌ மறுக்க முடியாது. கடல்‌ அலை\r\n",
        "உயரும்போது அனைத்துப்‌ படகுகளும்‌ ஒருசேர உயர்வது போல்‌,\r\n",
        "மாநிலத்தின்‌ துரிதமான பொருளாதார வளர்ச்சி, அனைத்துக்‌\r\n",
        "குடும்பங்களின்‌ பொருளாதார நிலையையும்‌ ஒருசேர உயர்த்தும்‌ என்பதில்‌\r\n",
        "ஐயமில்லை. எனினும்‌, சமுதாயத்தில்‌ அனைத்து மக்களின்‌ வாழ்வையும்‌\r\n",
        "மேம்படுத்தி, ஏற்றத்தாழ்வுகளைக்‌ களைந்து, பொருளாதாரச்‌ சம\r\n",
        "நிலையைக்‌ கொண்டு வருவதற்காக, பல்வேறு நலத்திட்டங்களை,\r\n",
        "குறிப்பாக ஏழை எளிய மக்களின்‌ மேம்பாட்டிற்கான திட்டங்களை\r\n",
        "இந்த அரசு தொடர்ந்து செயல்படுத்தும்‌. எனவே, பொருளாதார\r\n",
        "மேம்பாட்டிற்கு பெரும்‌ ஊக்கம்‌ தரும்‌ அதே வேளையில்‌, நலத்திட்டப்‌\r\n",
        "\fபணிகளும்‌ இந்த அரசின்‌ வளர்ச்சிக்‌ கொள்கையில்‌ தொடர்ந்து\r\n",
        "\r\n",
        "'''"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry8XNs18Dzno"
      },
      "source": [
        "# with open('/content/drive/MyDrive/tam_0_2.txt','r') as file:\n",
        "#   content = file.read()\n",
        "src = temp \n",
        "# tgtp = content\n",
        "res = phrase_aligner(src, tgtp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRe9VNFCdJDS",
        "outputId": "17c26aea-d77e-4b95-f81b-40fb2578fcf8"
      },
      "source": [
        "print(res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'tgt': 'भारत का संविधान अप्रैल,  को यथाविद्यमान संसद्\\u200c द्वारा समयसमय पर यथा संशोधित भारत केसंविधान के पाठ को उद्धृत करता है । संसद्\\u200c द्वारा, संविधान (एक सौ तीनवां संशोधन) अधिनियम, तक और उसको सम्मिलित करते हुए, किए गए सभी संशोधन, इस संस्करण मैं सम्मिलित किए गएहै । पाठ के नीचे दिए गए पाद टिप्पण, संविधान संशोधन अधिनियमों, जिसके द्वारा ऐसे संशोधन किएगए है, को उपदर्शित करता है ।', 'src_phrases': ['This edition of the Constitution of India reproduces the text of the Constitution of India as amended by Parliament from time to time', ' All amendments made by the Parliament up to and including the Constitution (One Hundred and Third Amendment) Act, 2019 are incorporated in this edition', 'The foot notes below the text indicate the Constitution Amendment Acts by which such amendments have been made', ''], 'aligned_phrases': {'This edition of the Constitution of India reproduces the text of the Constitution of India as amended by Parliament from time to time': 'को यथाविद्यमान संसद्\\u200c द्वारा समयसमय पर यथा संशोधित भारत केसंविधान के पाठ को उद्धृत करता है । संसद्\\u200c द्वारा, संविधान (एक सौ', ' All amendments made by the Parliament up to and including the Constitution (One Hundred and Third Amendment) Act, 2019 are incorporated in this edition': 'है । संसद्\\u200c द्वारा, संविधान (एक सौ तीनवां संशोधन) अधिनियम, तक और उसको सम्मिलित करते हुए, किए गए सभी संशोधन, इस संस्करण मैं सम्मिलित', 'The foot notes below the text indicate the Constitution Amendment Acts by which such amendments have been made': 'पाठ के नीचे दिए गए पाद टिप्पण, संविधान संशोधन अधिनियमों, जिसके द्वारा ऐसे संशोधन किएगए है, को उपदर्शित करता', '': ''}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qr_cbzdqPEwZ",
        "outputId": "2679b945-8b9a-49df-c6f4-8100fb5ecb2c"
      },
      "source": [
        "print(res['aligned_phrases'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'This edition of the Constitution of India reproduces the text of the Constitution of India as amended by Parliament from time to time': 'को यथाविद्यमान संसद्\\u200c द्वारा समयसमय पर यथा संशोधित भारत केसंविधान के पाठ को उद्धृत करता है । संसद्\\u200c द्वारा, संविधान (एक सौ', ' All amendments made by the Parliament up to and including the Constitution (One Hundred and Third Amendment) Act, 2019 are incorporated in this edition': 'है । संसद्\\u200c द्वारा, संविधान (एक सौ तीनवां संशोधन) अधिनियम, तक और उसको सम्मिलित करते हुए, किए गए सभी संशोधन, इस संस्करण मैं सम्मिलित', 'The foot notes below the text indicate the Constitution Amendment Acts by which such amendments have been made': 'पाठ के नीचे दिए गए पाद टिप्पण, संविधान संशोधन अधिनियमों, जिसके द्वारा ऐसे संशोधन किएगए है, को उपदर्शित करता', '': ''}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_3yt0PHdy-L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAX_20nBcWKa",
        "outputId": "41ed5ace-5045-41bc-9b8e-843eb0f774e0"
      },
      "source": [
        "for key in res['aligned_phrases']:\n",
        "  print(key)\n",
        "  print(res['aligned_phrases'][key])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This edition of the Constitution of India reproduces the text of the Constitution of India as amended by Parliament from time to time\n",
            "को यथाविद्यमान संसद्‌ द्वारा समयसमय पर यथा संशोधित भारत केसंविधान के पाठ को उद्धृत करता है । संसद्‌ द्वारा, संविधान (एक सौ\n",
            " All amendments made by the Parliament up to and including the Constitution (One Hundred and Third Amendment) Act, 2019 are incorporated in this edition\n",
            "है । संसद्‌ द्वारा, संविधान (एक सौ तीनवां संशोधन) अधिनियम, तक और उसको सम्मिलित करते हुए, किए गए सभी संशोधन, इस संस्करण मैं सम्मिलित\n",
            "The foot notes below the text indicate the Constitution Amendment Acts by which such amendments have been made\n",
            "पाठ के नीचे दिए गए पाद टिप्पण, संविधान संशोधन अधिनियमों, जिसके द्वारा ऐसे संशोधन किएगए है, को उपदर्शित करता\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r12nG251cha3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}