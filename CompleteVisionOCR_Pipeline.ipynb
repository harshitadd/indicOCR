{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CompleteVisionOCR_Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmF6JOJjlCIhlARO8j2EJy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitadd/AI4BharatTranslation/blob/main/CompleteVisionOCR_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pei7_7ycijLy"
      },
      "source": [
        "### Parse PDFs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCIX3S7LijL2"
      },
      "source": [
        "import logging\n",
        "import os\n",
        "import json\n",
        "from time import sleep\n",
        "import glob\n",
        "import requests"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdxKLvUiijL5"
      },
      "source": [
        "\n",
        "word_url = \"https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/async/initiate\"\n",
        "google_url = \"https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/async/initiate\"\n",
        "layout_url = \"https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/async/initiate\"\n",
        "segmenter_url = \"https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/async/initiate\"\n",
        "bs_url =\"https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/jobs/search/bulk\"\n",
        "\n",
        "evaluator_url  = \"https://auth.anuvaad.org/anuvaad-etl/document-processor/evaluator/v0/process\"\n",
        "\n",
        "#evaluator_url = 'http://0.0.0.0:5001/anuvaad-etl/document-processor/evaluator/v0/process'\n",
        "\n",
        "download_url =\"https://auth.anuvaad.org/download/\"\n",
        "upload_url = 'https://auth.anuvaad.org/anuvaad-api/file-uploader/v0/upload-file'\n",
        "token = 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyTmFtZSI6ImhhcnNoaXRhZGRAZ21haWwuY29tIiwicGFzc3dvcmQiOiJiJyQyYiQxMiRQcXNHOXRNRUIvSWxVVTAvcHRiSjFPL2Z2US4va1ZrUzl2QVlPWEQvL0RrdnJFN1JPZkV1TyciLCJleHAiOjE2MTQ3NDcwNzd9.hRd3FvlOaIqHEnOHvg9hZJvslBg4jk_4fH0vQZpjyV4'\n",
        "\n",
        "\n",
        "headers = {\n",
        "    'auth-token' :token }\n",
        "language = 'detect'\n",
        "file_format = 'PDF'\n",
        "\n",
        "evaluation_level = 'LINE'"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUor0lrOjAQF",
        "outputId": "811fdb76-c354-4e79-ef86-dde399a61197"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AGi6X4xijL6"
      },
      "source": [
        "source_pdfs = \"/content/drive/MyDrive/Ta/Test/\"\n",
        "parsed_pdf_dir = \"/content/drive/MyDrive/Ta/Test/parsed/\"\n",
        "text_dir = \"/content/drive/MyDrive/Ta/Test/text/\"\n",
        "sentences_dir = \"/content/drive/MyDrive/Ta/Test/sent/\"\n",
        "aligned_sentences_path = \"/content/drive/MyDrive/Ta/Test/aligned/\""
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNsiDf3mijL7"
      },
      "source": [
        "def google_ocr(word_url,headers,pdf_name):\n",
        "    \n",
        "    file = {\n",
        "       \"files\": [\n",
        "        {\n",
        "            \"locale\": \"en\",\n",
        "            \"path\": pdf_name,\n",
        "            \"type\": file_format,\n",
        "            \"config\":{\n",
        "        \"OCR\": {\n",
        "          \"option\": \"HIGH_ACCURACY\",\n",
        "          \"language\": language\n",
        "        }\n",
        "        }}\n",
        "    ],\n",
        "    \"workflowCode\": \"WF_A_OGV\"\n",
        "    }\n",
        "    res = requests.post(word_url,json=file,headers=headers)\n",
        "    return res.json()\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5WiTdhUijL9"
      },
      "source": [
        "def upload_file(pdf_file,headers,url):\n",
        "    #url = 'https://auth.anuvaad.org/anuvaad-api/file-uploader/v0/upload-file'\n",
        "    files = [\n",
        "        ('file',(open(pdf_file,'rb')))] \n",
        "\n",
        "    response = requests.post(url, headers=headers, files=files)\n",
        "    \n",
        "    return response.json()\n",
        "    response.json()\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIg-zhdbijL-"
      },
      "source": [
        "def download_file(download_url,headers,outputfile,f_type='json'):\n",
        "    download_url =download_url+str(outputfile)\n",
        "    res = requests.get(download_url,headers=headers)\n",
        "    if f_type == 'json':\n",
        "        return res.json()\n",
        "    else :\n",
        "        return res.content"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyuegZ5pijL-"
      },
      "source": [
        "def save_json(path,res):\n",
        "    with open(path, \"w\", encoding='utf8') as write_file:\n",
        "        json.dump(res, write_file,ensure_ascii=False )\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9jEqTOoijL_"
      },
      "source": [
        "def bulk_search(job_id,bs_url,headers):\n",
        "    bs_request = {\n",
        "    \"jobIDs\": [job_id],\n",
        "    \"taskDetails\":\"true\"\n",
        "    }\n",
        "    print(job_id)\n",
        "    res = requests.post(bs_url,json=bs_request,headers=headers, timeout = 10000)\n",
        "    print(res.json())\n",
        "    prev_progress = \"\"\n",
        "   \n",
        "    while(1):\n",
        "        \n",
        "        progress = res.json()['jobs'][0]['status']\n",
        "       \n",
        "        if progress in ['COMPLETED','FAILED']:\n",
        "            print(progress)\n",
        "            outputfile = res.json()['jobs'][0]['taskDetails'][0]['output'][0]['outputFile']\n",
        "            print(outputfile)\n",
        "            print(job_id)\n",
        "            return outputfile\n",
        "            break\n",
        "        sleep(0.5)\n",
        "        if progress != prev_progress:\n",
        "            print(progress)\n",
        "            prev_progress = progress\n",
        "        res = requests.post(bs_url,json=bs_request,headers=headers, timeout = 10000)\n",
        "        #print(res.json())"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN3aiM5hijMA"
      },
      "source": [
        "def bulk_search_all(job_id,bs_url,headers):\n",
        "    bs_request = {\n",
        "    \"jobIDs\": [job_id],\n",
        "    \"taskDetails\":\"true\"\n",
        "    }\n",
        "    print(job_id)\n",
        "    res = requests.post(bs_url,json=bs_request,headers=headers, timeout = 10000)\n",
        "    print(res.json())\n",
        "    \n",
        "   \n",
        "    while(1):\n",
        "        \n",
        "        progress = res.json()['jobs'][0]['status']\n",
        "       \n",
        "        if progress in ['COMPLETED','FAILED']:\n",
        "            print(progress)\n",
        "            outputfile = res.json()['jobs'][0]['taskDetails'][0]['output'][0]['outputFile']\n",
        "            print(outputfile)\n",
        "            print(job_id)\n",
        "            return outputfile\n",
        "            break\n",
        "        sleep(0.5)\n",
        "        print(progress)\n",
        "        res = requests.post(bs_url,json=bs_request,headers=headers, timeout = 10000)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMDGtmAhijMA"
      },
      "source": [
        "def execute_module(module,url,input_file,module_code,pdf_dir,overwirte=True , draw=True):\n",
        "    \n",
        "        \n",
        "        output_path = os.path.join(pdf_dir,'{}.json'.format(module_code))\n",
        "        if os.path.exists(output_path) and not overwirte:\n",
        "            print(' loading *****************{}'.format(module_code ))\n",
        "            with open(output_path,'r') as wd_file :\n",
        "                response = json.load(wd_file)\n",
        "                \n",
        "            wf_res = pdf_dir + '/{}_wf.json'.format(module_code)\n",
        "            with open(wf_res,'r') as wd_file :\n",
        "                json_file = json.load(wd_file) \n",
        "            #json_file = upload_file(output_path,headers,upload_url)['data']\n",
        "            job_to_add = (pdf_dir)\n",
        "\n",
        "        else :\n",
        "            if module_code in ['wd','gv']:\n",
        "                res = upload_file(input_file,headers,upload_url)\n",
        "                print('upload response **********', res)\n",
        "                pdf_name = res['data']\n",
        "                response = module(url,headers,pdf_name)\n",
        "            \n",
        "            else : \n",
        "                response = module(url,headers,input_file)\n",
        "                \n",
        "                if 'eval' in module_code :\n",
        "                    json_file = response['outputFile']\n",
        "                    response = download_file(download_url,headers,json_file)\n",
        "                    save_json(output_path,response)\n",
        "                    return json_file,response\n",
        "                \n",
        "            \n",
        "            print(' response *****************{} {}'.format(module_code ,response ))\n",
        "            job_id = response['jobID']\n",
        "            \n",
        "            job_to_add = (job_id,bs_url,headers,pdf_dir,module_code,output_path)\n",
        "#             json_file = bulk_search(job_id,bs_url,headers)\n",
        "#             save_json(pdf_dir + '/{}_wf.json'.format(module_code),json_file)   \n",
        "#             print('bulk search  response **************',json_file )\n",
        "#             response = download_file(download_url,headers,json_file)\n",
        "#             save_json(output_path,response)\n",
        "            \n",
        "#             if draw :\n",
        "#                 if module_code in ['wd','gv']:\n",
        "#                     Draw(response,pdf_dir,regions='lines',prefix=module_code)\n",
        "#                 else :\n",
        "#                      Draw(response,pdf_dir,regions='regions',prefix=module_code)\n",
        "        return job_to_add\n",
        "#         return json_file,response\n",
        "        \n",
        "            \n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEnzwRkfijMB"
      },
      "source": [
        "def evaluate__and_save_input(pdf_files,output_dir,headers,word_url,layout_url,download_url,upload_url,bs_url):\n",
        "    word_responses   = {}\n",
        "    layout_responses = {}\n",
        "    segmenter_responses = []\n",
        "    jobs_to_track = []\n",
        "    for pdf in pdf_files:\n",
        "        try :\n",
        "            pdf_name = pdf.split('/')[-1].split('.')[0]\n",
        "            parent_folder_name = pdf.split('/')[-2]\n",
        "            print(pdf , ' is being processed')\n",
        "            pdf_output_dir = os.path.join(output_dir,parent_folder_name,pdf_name)\n",
        "            os.system('mkdir -p \"{}\"'.format(pdf_output_dir))\n",
        "\n",
        "\n",
        "#             wd_json,_ = execute_module(word_detector,word_url,input_file=pdf,\\\n",
        "#                            module_code='wd',pdf_dir=pdf_output_dir,overwirte=False , draw=True)\n",
        "\n",
        "\n",
        "#             google_json,google_resposne = \n",
        "            job_to_add = execute_module(google_ocr,google_url,input_file=pdf,\\\n",
        "                           module_code='gv',pdf_dir=pdf_output_dir,overwirte=False , draw=False)\n",
        "            \n",
        "            jobs_to_track.append(job_to_add)\n",
        "#             ld_json,_ = execute_module(layout_detector,layout_url,input_file=wd_json,\\\n",
        "#                            module_code='ld',pdf_dir=pdf_output_dir,overwirte=False , draw=True)\n",
        "\n",
        "\n",
        "#             seg_json,_ = execute_module(block_segmenter,segmenter_url,input_file=ld_json,\\\n",
        "#                            module_code='seg',pdf_dir=pdf_output_dir,overwirte=False , draw=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#             tess_json,_= execute_module(tesseract_ocr,word_url,input_file=seg_json,\\\n",
        "#                         module_code='tess',pdf_dir=pdf_output_dir,overwirte=True , draw=True)\n",
        "\n",
        "\n",
        "#             evaluator_input= {'predicted': tess_json , 'ground':google_json ,'level': evaluation_level}\n",
        "\n",
        "#             eval_json ,evaluator_response = execute_module(evaluator,evaluator_url,\\\n",
        "#                                                            input_file=evaluator_input,module_code='eval_line', \\\n",
        "#                                                            pdf_dir= pdf_output_dir)\n",
        "\n",
        "\n",
        "#             error_df = find_erros(evaluator_response,google_resposne,iou_threshold=0.33)\n",
        "#             #error_df\n",
        "#             for page_index,page_row in error_df.iterrows():\n",
        "#                 img = draw_erros(page_row,page_index)\n",
        "#                 cv2.imwrite('{}/eval_{}_{}.png'.format(pdf_output_dir,evaluation_level,page_index),np.array(img).astype('uint8'))\n",
        "        \n",
        "\n",
        "          \n",
        "        except Exception as e : \n",
        "            print(e)\n",
        "            logging.error('error in file {}  \\n {}'.format(pdf_name,e))\n",
        "\n",
        " \n",
        "    for job in jobs_to_track:\n",
        "        print(\"----------\")\n",
        "        print(job)\n",
        "        job_id,bs_url,headers,pdf_dir,module_code,output_path = job\n",
        "        json_file = bulk_search(job_id,bs_url,headers)\n",
        "        save_json(pdf_dir + '/{}_wf.json'.format(module_code),json_file)   \n",
        "        print('bulk search  response **************',json_file )\n",
        "        response = download_file(download_url,headers,json_file)\n",
        "        save_json(output_path,response)\n",
        "\n",
        "    print(\"----------------\")\n",
        "    print(jobs_to_track)\n",
        "    print(\"----------------\")\n",
        "    return jobs_to_track"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mehfPhI3ijME"
      },
      "source": [
        "def main(path,headers,word_url,layout_url,download_url,upload_url,bs_url):\n",
        "        pdf_names = glob.glob(path + '/*/*.pdf')[:6]\n",
        "        pdf_names.reverse()\n",
        "#         print(pdf_names)\n",
        "        \n",
        "        return evaluate__and_save_input(pdf_names,parsed_pdf_dir,headers,word_url,layout_url,download_url,upload_url,bs_url)\n",
        "        "
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQUTVWf1ijMF"
      },
      "source": [
        "# bulk_search(\"A_OGV-BVBtL-1614524897583\",)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "xYF-tMAfijMF",
        "outputId": "0d5e3103-3de7-41c2-85fa-cfa29aa7f704"
      },
      "source": [
        "# path = \"/Users/eaxxkra/Downloads/tn_budget_formated/\"\n",
        "main(source_pdfs,headers,word_url,layout_url,download_url,upload_url,bs_url)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Ta/Test/426/en_426_en.pdf  is being processed\n",
            " loading *****************gv\n",
            "/content/drive/MyDrive/Ta/Test/426/ta_426_ta.pdf  is being processed\n",
            " loading *****************gv\n",
            "/content/drive/MyDrive/Ta/Test/430/en_430_en.pdf  is being processed\n",
            " loading *****************gv\n",
            "/content/drive/MyDrive/Ta/Test/430/ta_430_ta.pdf  is being processed\n",
            " loading *****************gv\n",
            "/content/drive/MyDrive/Ta/Test/428/en_428_en.pdf  is being processed\n",
            " loading *****************gv\n",
            "/content/drive/MyDrive/Ta/Test/428/ta_428_ta.pdf  is being processed\n",
            " loading *****************gv\n",
            "----------\n",
            "/content/drive/MyDrive/Ta/Test/parsed/426/en_426_en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-bf549f9b62aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# path = \"/Users/eaxxkra/Downloads/tn_budget_formated/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_pdfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayout_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdownload_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mupload_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-65-f2d04bd7cff2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(path, headers, word_url, layout_url, download_url, upload_url, bs_url)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#         print(pdf_names)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mevaluate__and_save_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparsed_pdf_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayout_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdownload_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mupload_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-e835e0a0f6ee>\u001b[0m in \u001b[0;36mevaluate__and_save_input\u001b[0;34m(pdf_files, output_dir, headers, word_url, layout_url, download_url, upload_url, bs_url)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpdf_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodule_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mjson_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbulk_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0msave_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/{}_wf.json'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 6)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dvFd6woijMI"
      },
      "source": [
        "### Json to text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pWeLcfkijMI"
      },
      "source": [
        "def extract_text(parent,folder_name):\n",
        "    with open(parsed_pdf_dir + f\"{parent}/{folder_name}/gv.json\",'r') as f:\n",
        "        data = json.load(f)\n",
        "    pages = data['outputs'][0]['pages']\n",
        "    all_texts = []\n",
        "    for page in pages:\n",
        "        page_text = []\n",
        "        lines = page['lines']\n",
        "        for line in lines:\n",
        "            page_text.append(line['text'])\n",
        "        all_texts.append(page_text)\n",
        "    all_lines = [line for al in all_texts for line in al]\n",
        "    all_text = \" \".join(all_lines)\n",
        "    lang = folder_name[-2:]\n",
        "    os.system('mkdir -p \"{}\"'.format(text_dir + f\"{parent}\"))\n",
        "    with open(text_dir + f\"{parent}/{folder_name}.txt\",'w',encoding='utf-16') as f:\n",
        "        f.writelines(all_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P6WFtQDijMJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd776d52-45d6-431f-d65a-f78983d41a05"
      },
      "source": [
        "import glob\n",
        "import shutil\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "failed_parses = []\n",
        "for name in glob.glob(parsed_pdf_dir + '/*/*'):\n",
        "    folder_name = name.replace(parsed_pdf_dir,\"\")\n",
        "    print(folder_name)\n",
        "    parent ,folder_name = folder_name.split(\"/\")\n",
        "    try:\n",
        "        extract_text(parent,folder_name)\n",
        "    except:\n",
        "        print(folder_name)\n",
        "        failed_parses.append(folder_name)\n",
        "        \n",
        "for folder_name in failed_parses:\n",
        "    dirpath = Path(text_dir + f\"{folder_name}\")\n",
        "    if dirpath.exists():\n",
        "        shutil.rmtree(dirpath)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "426/en_426_en\n",
            "426/ta_426_ta\n",
            "430/en_430_en\n",
            "430/ta_430_ta\n",
            "428/en_428_en\n",
            "428/ta_428_ta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmUrmN3wijMJ"
      },
      "source": [
        "### Sentence Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhZEv7ucijMJ"
      },
      "source": [
        "def upload_file(file):\n",
        "    url = 'https://auth.anuvaad.org/anuvaad-api/file-uploader/v0/upload-file'\n",
        "    files = [\n",
        "        ('file',(open(file,'rb')))] \n",
        "\n",
        "    response = requests.post(url, headers=headers, files=files)\n",
        "    print(response.json())\n",
        "    return response.json()['data']\n",
        "\n",
        "def tokenize_text(file_path,lang):\n",
        "    body = {\"files\": [\n",
        "            {\n",
        "              \"locale\": lang,\n",
        "              \"path\": file_path,\n",
        "              \"type\": \"txt\",\n",
        "              \"text\": [\"TEST\"]\n",
        "            }]}\n",
        "    url = \"https://auth.anuvaad.org/anuvaad-etl/tokeniser/v0/tokenisation\"\n",
        "    response = requests.post(url, headers=headers,json=body).json()\n",
        "    print(response)\n",
        "    if \"output\" in response:\n",
        "        return response['output'][0]['outputFile']\n",
        "    return None\n",
        "\n",
        "def tokenize_texts(file_path_lang_tup_list):\n",
        "    files = []\n",
        "    for file,lang in file_path_lang_tup_list:\n",
        "        files.append({\n",
        "              \"locale\": lang,\n",
        "              \"path\": file,\n",
        "              \"type\": \"txt\",\n",
        "              \"text\": [\"TEST\"]\n",
        "            })\n",
        "    body = {\"files\": files}\n",
        "    url = \"https://auth.anuvaad.org/anuvaad-etl/tokeniser/v0/tokenisation\"\n",
        "    response = requests.post(url, headers=headers,json=body)\n",
        "    print(response.json())\n",
        "    a = [output['outputFile'] for output in response.json()['output']]\n",
        "    print(a)\n",
        "    return a\n",
        "\n",
        "def download_file(outputfile):\n",
        "\n",
        "    download_url =\"https://auth.anuvaad.org/download/\"+str(outputfile)\n",
        "    res = requests.get(download_url,headers=headers)\n",
        "    return res.content"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7cmxBZWijMK"
      },
      "source": [
        "# input_path = \"/Users/eaxxkra/Downloads/tn_budget_text/*/*.txt\"\n",
        "# output_path = \"/Users/eaxxkra/Downloads/tn_budget_sentences/\""
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7QjR5NFSijMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13cb082-9a5e-4606-ee1e-82638e23b3e5"
      },
      "source": [
        "for file in glob.glob(text_dir+ \"*/*.txt\"):\n",
        "    failed_files = []\n",
        "    lang = file.split(\".txt\")[0].split(\"_\")[-1]\n",
        "    file_path = upload_file(file)\n",
        "    print(file_path)\n",
        "    tokenized_file_id = tokenize_text(file_path,lang)\n",
        "    if tokenized_file_id:\n",
        "        content = download_file(tokenized_file_id)\n",
        "        os.system('mkdir -p \"{}\"'.format(sentences_dir+ file.split(\"/\")[-2]))\n",
        "        write_path = sentences_dir+ file.split(\"/\")[-2] + \"/\" + file.split(\"/\")[-1]\n",
        "        with open(write_path,'w',encoding=\"utf-16\") as f:\n",
        "            f.writelines(content.decode('utf-16'))\n",
        "    else:\n",
        "        print('Failed')\n",
        "        failed_files.append((file_path,lang))\n",
        "failed_files_again = []\n",
        "for file_path,lang in failed_files:\n",
        "    tokenized_file_id = tokenize_text(file_path,lang)\n",
        "    if tokenized_file_id:\n",
        "        content = download_file(tokenized_file_id)\n",
        "        os.system('mkdir -p \"{}\"'.format(sentences_dir+ file.split(\"/\")[-2]))\n",
        "        write_path = sentences_dir+ file.split(\"/\")[-2] + \"/\" + file.split(\"/\")[-1]\n",
        "        with open(write_path,'w',encoding=\"utf-16\") as f:\n",
        "            f.writelines(content.decode('utf-16'))\n",
        "    else:\n",
        "        failed_files_again.append((file_path,lang))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data': '155a17c0-78e9-46c2-9483-1e5e9a812288.txt', 'http': {'status': 200}, 'ok': True, 'why': 'request successful'}\n",
            "155a17c0-78e9-46c2-9483-1e5e9a812288.txt\n",
            "{'jobID': 'A_FBTTR-elmhk-1614679472104', 'output': [{'inputFile': '155a17c0-78e9-46c2-9483-1e5e9a812288.txt', 'outputFile': '0-16146857546890845.txt', 'outputLocale': 'en', 'outputType': 'txt'}], 'state': 'SENTENCE-TOKENISED', 'status': 'SUCCESS', 'stepOrder': 2, 'taskEndTime': 1614679524478, 'taskID': 'TOK-1614679524388', 'taskStarttime': 1614679524388, 'tool': 'TOKENISER', 'workflowCode': 'WF_A_FCBMTKTR'}\n",
            "{'data': 'a7cb1972-aa02-429c-ba18-263ce10f8073.txt', 'http': {'status': 200}, 'ok': True, 'why': 'request successful'}\n",
            "a7cb1972-aa02-429c-ba18-263ce10f8073.txt\n",
            "{'jobID': 'A_FBTTR-sezQm-1614682207785', 'output': [{'inputFile': 'a7cb1972-aa02-429c-ba18-263ce10f8073.txt', 'outputFile': '0-16146857627344723.txt', 'outputLocale': 'ta', 'outputType': 'txt'}], 'state': 'SENTENCE-TOKENISED', 'status': 'SUCCESS', 'stepOrder': 2, 'taskEndTime': 1614682238884, 'taskID': 'TOK-1614682238720', 'taskStarttime': 1614682238720, 'tool': 'TOKENISER', 'workflowCode': 'WF_A_FCBMTKTR'}\n",
            "{'data': 'a1c0e96b-25ee-4b1b-889e-e4657b198547.txt', 'http': {'status': 200}, 'ok': True, 'why': 'request successful'}\n",
            "a1c0e96b-25ee-4b1b-889e-e4657b198547.txt\n",
            "{'jobID': 'A_FBTTR-aJCox-1614682576011', 'output': [{'inputFile': 'a1c0e96b-25ee-4b1b-889e-e4657b198547.txt', 'outputFile': '0-161468577094926.txt', 'outputLocale': 'en', 'outputType': 'txt'}], 'state': 'SENTENCE-TOKENISED', 'status': 'SUCCESS', 'stepOrder': 2, 'taskEndTime': 1614682653064, 'taskID': 'TOK-1614682652553', 'taskStarttime': 1614682652553, 'tool': 'TOKENISER', 'workflowCode': 'WF_A_FCBMTKTR'}\n",
            "{'data': '78972bdb-9b45-4f82-89b6-59caccca9a45.txt', 'http': {'status': 200}, 'ok': True, 'why': 'request successful'}\n",
            "78972bdb-9b45-4f82-89b6-59caccca9a45.txt\n",
            "{'jobID': 'A_FBTTR-aJCox-1614682576011', 'output': [{'inputFile': '78972bdb-9b45-4f82-89b6-59caccca9a45.txt', 'outputFile': '0-16146857786565647.txt', 'outputLocale': 'ta', 'outputType': 'txt'}], 'state': 'SENTENCE-TOKENISED', 'status': 'SUCCESS', 'stepOrder': 2, 'taskEndTime': 1614682653064, 'taskID': 'TOK-1614682652553', 'taskStarttime': 1614682652553, 'tool': 'TOKENISER', 'workflowCode': 'WF_A_FCBMTKTR'}\n",
            "{'data': '8e82023d-04d0-4b62-b462-d9a2cc12430e.txt', 'http': {'status': 200}, 'ok': True, 'why': 'request successful'}\n",
            "8e82023d-04d0-4b62-b462-d9a2cc12430e.txt\n",
            "{'Errors': [{'code': 'ZuulRuntimeException', 'message': 'com.netflix.zuul.exception.ZuulException: Forwarding error'}]}\n",
            "Failed\n",
            "{'data': 'a099c2ff-5407-432b-8de4-d38d1a7a11fe.txt', 'http': {'status': 200}, 'ok': True, 'why': 'request successful'}\n",
            "a099c2ff-5407-432b-8de4-d38d1a7a11fe.txt\n",
            "{'jobID': 'A_FBTTR-elmhk-1614679472104', 'output': [{'inputFile': 'a099c2ff-5407-432b-8de4-d38d1a7a11fe.txt', 'outputFile': '0-16146858532317967.txt', 'outputLocale': 'ta', 'outputType': 'txt'}], 'state': 'SENTENCE-TOKENISED', 'status': 'SUCCESS', 'stepOrder': 2, 'taskEndTime': 1614679524478, 'taskID': 'TOK-1614679524388', 'taskStarttime': 1614679524388, 'tool': 'TOKENISER', 'workflowCode': 'WF_A_FCBMTKTR'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqeq-AANwT6o"
      },
      "source": [
        ""
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYKQJjP-ijML"
      },
      "source": [
        "### Sentence Alignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2OjeOYDijML"
      },
      "source": [
        "upload_url = \"https://auth.anuvaad.org/anuvaad-api/file-uploader/v0/upload-file\"\n",
        "aligner_url = \"https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/async/initiate\"\n",
        "download_url = \"https://auth.anuvaad.org/download/\"\n",
        "search_url = \"'https://auth.anuvaad.org/anuvaad-etl/wf-manager/v1/workflow/jobs/search/bulk'\"\n",
        "\n",
        "# input_path = \"/Users/eaxxkra/Downloads/tn_budget_sentences/\"\n",
        "# output_path = \"/Users/eaxxkra/Downloads/tn_budget_aligned_sentences/\""
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "r0JROMlgijML",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "2b256b04-5671-48fd-b46e-320b77dfcebd"
      },
      "source": [
        "def bulk_search_alignment(job_id,bs_url,headers):\n",
        "    bs_request = {\n",
        "    \"jobIDs\": [job_id],\n",
        "    \"taskDetails\":\"true\"\n",
        "    }\n",
        "    print(job_id)\n",
        "    res = requests.post(bs_url,json=bs_request,headers=headers, timeout = 10000)\n",
        "    prev_progress = \"\"\n",
        "   \n",
        "    while(1):\n",
        "        \n",
        "        progress = res.json()['jobs'][0]['status']\n",
        "       \n",
        "        if progress in ['COMPLETED','FAILED']:\n",
        "            print(progress)\n",
        "            data = res.json()\n",
        "            secondlanguage = data['jobs'][0]['input']['files'][0]['locale']    \n",
        "            print(secondlanguage)\n",
        "            source , target = \"source\" , \"target\"\n",
        "            if secondlanguage == 'en.txt':\n",
        "                source , target = target, source\n",
        "            nomatch=str(data['jobs'][0]['output']['noMatch']['source'])\n",
        "            match_english=str(data['jobs'][0][\"output\"]['match'][target])\n",
        "            match_non_english=str(data['jobs'][0][\"output\"]['match'][source])\n",
        "            almostmatch_english=str(data['jobs'][0]['output']['almostMatch'][target])\n",
        "            almostatch_non_english=str(data['jobs'][0]['output']['almostMatch'][source])\n",
        "            return {\n",
        "                'match_english' : match_english,\n",
        "                'match_non_english' : match_non_english,\n",
        "                'almost_match_english' : almostmatch_english,\n",
        "                'almost_non_match_english' : almostatch_non_english,\n",
        "                'no_match' : nomatch}\n",
        "            break\n",
        "        sleep(0.5)\n",
        "        if progress != prev_progress:\n",
        "            print(progress)\n",
        "            prev_progress = progress\n",
        "        res = requests.post(bs_url,json=bs_request,headers=headers, timeout = 10000)\n",
        "        #print(res.json())\n",
        "\n",
        "def upload_files(folder):\n",
        "    path_lang_tup = []\n",
        "    for file in glob.glob(folder+\"/*\"):\n",
        "        print(file)\n",
        "        lang = file.split(\"_\")[-1]        \n",
        "        path_lang_tup.append((upload_file(file),lang))\n",
        "    return path_lang_tup\n",
        "\n",
        "def submit_alignment_job(path_lang_tup):\n",
        "    print(path_lang_tup)\n",
        "    files = []\n",
        "    for path, lang in path_lang_tup:\n",
        "        files.append({\n",
        "                        \"locale\": lang,\n",
        "                        \"path\": path,\n",
        "                        \"type\": \"txt\"\n",
        "                    })\n",
        "    \n",
        "    \n",
        "    aligner_body = {\n",
        "        \"workflowCode\":\"WF_A_AL\",\n",
        "        \"files\": files}\n",
        "    \n",
        "    aligner_response = requests.request(\"POST\", aligner_url, json=aligner_body, headers=headers).json()\n",
        "    return aligner_response['jobID']\n",
        "    \n",
        "jobs_to_track = []\n",
        "for folder in glob.glob(sentences_dir+\"/*\"):\n",
        "    print(folder)\n",
        "    path_lang_tup = upload_files(folder)\n",
        "    job_id = submit_alignment_job(path_lang_tup)\n",
        "    jobs_to_track.append((job_id,folder.split(\"/\")[-1]))\n",
        "\n",
        "for job_id, folder in jobs_to_track:\n",
        "    file_to_download = bulk_search_alignment(job_id,bs_url,headers)\n",
        "    for key , value in file_to_download.items():\n",
        "        content = download_file(value)\n",
        "        os.system('mkdir -p \"{}\"'.format(aligned_sentences_path+folder))\n",
        "        with open(os.path.join(aligned_sentences_path,folder,f\"{key}.text\"),'w',encoding=\"utf-16\") as f:\n",
        "            f.writelines(content.decode('utf-16'))"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Ta/Test/sent/Tourism\n",
            "/content/drive/MyDrive/Ta/Test/sent/Tourism/TNTourism_Tam_ta.txt\n",
            "{'data': '6e3b4997-55ca-451c-8fdc-6491b862e357.txt', 'http': {'status': 200}, 'ok': True, 'why': 'request successful'}\n",
            "/content/drive/MyDrive/Ta/Test/sent/Tourism/TNTourism_Eng_ta.txt\n",
            "{'data': '5008c51a-7d4a-4240-aa1d-427dfe1159c7.txt', 'http': {'status': 200}, 'ok': True, 'why': 'request successful'}\n",
            "[('6e3b4997-55ca-451c-8fdc-6491b862e357.txt', 'ta.txt'), ('5008c51a-7d4a-4240-aa1d-427dfe1159c7.txt', 'ta.txt')]\n",
            "A_A-hXLVo-1614672073895\n",
            "INPROGRESS\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-166-1b03c6cd2e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs_to_track\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mfile_to_download\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbulk_search_alignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_to_download\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-166-1b03c6cd2e32>\u001b[0m in \u001b[0;36mbulk_search_alignment\u001b[0;34m(job_id, bs_url, headers)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mprev_progress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs_request\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;31m#print(res.json())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mca_cert_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca_cert_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             ssl_context=context)\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_fingerprint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir)\u001b[0m\n\u001b[1;32m    343\u001b[0m             or IS_SECURETRANSPORT):\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mserver_hostname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         warnings.warn(\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         )\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m    868\u001b[0m                         \u001b[0;31m# non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}